\documentclass[oneside,a4paper,english,links]{amca}
%
\usepackage{graphicx}
\usepackage{amsmath,amsfonts}

\title{REAL TIME DIRECT VOLUME RENDERING OF BREAD CRUMBS}

\author[a]{Rodrigo Baravalle}
\author[b]{Leonardo Scandolo}
\author[c]{Claudio Delrieux}
\author[d]{Cristian G. Bauza}
%
\affil[a]{Laboratory for System Dynamics and Signal Processing, FCEIA, Rosario National University, CIFASIS-CONICET,
  Ocampo y Esmeralda, S2000EZP~Rosario, Argentina,
  baravalle@cifasis-conicet.gov.ar, \url{http://www.cifasis-conicet.gov.ar/grupo4.html}}
%
\affil[b]{Computer Science Department, FCEIA, Rosario National University,
  Pellegrini 250, 2000~Rosario, Argentina,
  leonardo@fceia.unr.edu.ar, \url{http://web.fceia.unr.edu.ar/es/institucional/escuelas/118-departamento-ciencias-de-la-computacion-ecen.html}}

\affil[c]{Department of Electrical Engineering and Computers, Universidad Nacional del Sur - IIIE-CONICET,
  Col\'on 80, 8000FTN~Bah\'ia Blanca, Argentina,
  cad@uns.edu.ar, \url{http://www.ingelec.uns.edu.ar/}}

\affil[d]{Research Institute PLADEMA- Faculty of Exact Sciences - Universidad Nacional del Centro,
  Paraje Arroyo Seco, (B7001BBO) Tandil, Buenos Aires, Argentina
  crgarcia@exa.unicen.edu.ar, \url{http://www.exa.unicen.edu.ar/es/d_investigacion/inst_pladema/index.html}}


%% NOTE: IF ALL AUTHORS BELONG TO THE SAME AFFILIATION
%% USE THE `\voidaffil' MACRO FOR THE AFFILIATION CODE.
%% Example:
%% \author[\voidaffil]{First A. Author}
%% \author[\voidaffil]{Second B. Author}
%% \author[\voidaffil]{Third C. Author}
%% \author[\voidaffil]{Fourth D. Author}
%% %
%% \affil[\voidaffil]{Grupo de Mec\'anica Computacional,
%% Universidad Nacional de Villa Carolina,
%% Los Alerces 3492, 4200 Villa Carolina, Argentina,
%% gmc@uncarolina.edu.ar, http://www.uncarolina.edu.ar/gmc}

\begin{document}
\vspace{3cm}

\maketitle

%% To set PDF METADATA: uncomment and replace fields in
%% UPPERCASE with appropriate values. 
%% 
%% \hypersetup{
%%   pdfauthor={AUTHORS},
%%   pdfkeywords={KEYWORDS},
%%   pdftitle={TITLE}
%% }
%%
%% For instance
%% \hypersetup{
%%   pdfauthor={Sponge B. and Star P.},
%%   pdfkeywords={multiphase flow, air-liquid mixtures},
%%   pdftitle={A new model for multi-phase flow}
%% }
%%
%% NOTE: To set the metadata is recommended but not absolutely
%% neccesary. 
%% This was done before with the \pdfinfo command,
%% but according to this post:
%% http://de.nntp2http.com/comp/text/tex/2008/12/5358fd061de9703a781885a5dcf98364.html
%% if `hyperref' is used, then you must use \hypersetup{} not \pdfinfo{}

\begin{keywords}
  Direct Volume Rendering, Bread Crumb, Real Time.
\end{keywords}

\begin{abstract}
  Photo-realistic modelling and rendering of materials with complex internal structure poses a hard challenge in the Computer Graphics community. In particular, bread crumbs consist of a complex translucent material with a porous structure that presents different details at different scales. Realistic bread crumb rendering involves several light phenomena such as subsurface scattering, self-shadowing, self-occlusion, reflectance, and absorption. Current approaches to realistic recreate these phenomena use an  approximation of the rendering equation ({\em i.e.}, they account for global illumination as in ray and path tracing). Nevertheless, they are computationally expensive and generally require a detailed bread crumb mesh.

  State of the art techniques for bread crumb rendering set up a complex capture procedure, in which the light reflecting off the material is sampled at different angles. The methods use that information to reconstruct a material model. While this solution accounts for several desired properties of this material, it presents several drawbacks which makes difficult its practical applications: high computational costs, complex capture procedures, and poor image variability.

  In this work we propose to study and implement a GPU based direct volume rendering on a scalar field to represent the internal structure of a bread crumb, without requiring any intermediate steps. The images obtained show promising results at interactive and real time frame rates. We represent the crumb as a 3D scalar field, computing it in two steps. The first uses a particle-system based generation procedure, and the second uses dynamic systems to evolve the particles mimicking the bread making process.
\end{abstract}

\section{INTRODUCTION}

The computer graphics community has considered challenging to render the appearance of  baked materials, such as
pizzas and cookies, due to
the complex interaction of light outside and inside the
material. Computational costs of these
physical simulations made its rendering impractical in areas with high
interaction with the final user. The exponential growth in
computing power, based on the massively parallel design of modern
graphics cards \citep{Yeo09,Harris06}, has made it possible to
simulate some light phenomena at acceptable computational rates, but
the field is still a subject of research \citep{Voglsam2013}.

The geometry of these materials represents an additional challenge. These porous structures are the
result of complex mechanisms involving physical deformations and
chemical reactions. Bread making involves two different
processes: proofing and baking. Proofing accounts for
chemical reactions between the living yeast and the dough. The yeast
produces $CO_{2}$ making bubbles in the dough
\citep{Shah1998}. In the baking process \citep{Mondal2008},
temperature changes these shapes in several ways \citep{Scanlon2001},
giving bread its final internal structure. The literature reports a few attempts to
synthesise a model of the resulting geometrical structure \citep{VanDyck2014,Cho2007}, but the process is an artistic design or its variability is limited to the amount of captures
made. In this work we propose to employ dynamical systems
\citep{Strogatz2001} in order to evolve particle systems
\citep{Reeves83}, which we have previously designed
\citep{Baravalle2011}, trying to mimic the bread making process
(proofing and baking). Differential equations govern many complex processes, such as weather and
fluids, describing their
dynamics and appearance. We employ this idea
to describe bubble growth in bread. This process produces a
structure similar to bubbles growing inside a fluid. Other approaches compute
texel values using algebraic functions without requiring to
store a 3D texture in memory \citep{Perlin1989}, but they
are not adequate since bubble distributions are difficult to
model statistically.

The mechanism for rendering the internal constitution of these materials largely depends
on the data structure chosen for its representation. Triangular
meshes should be computed from voxel data, using
techniques such as marching cubes \citep{Lorensen1987}. Nevertheless
the porous bread structure makes it a non-trivial task, and it
could be high memory demanding.

The presence of mesostructures (surface bubbles) makes bread a quasi homogeneous material \citep{Tong2005}. Surface representations
of this material are not adequate since it presents visible structures on it: typical solutions such as
Bidirectional Reflectance Distribution Functions (BRDF)
\citep{Kurt2009} and Bidirectional Surface Scattering Reflectance
Distribution Functions (BSSRDF) \citep{Donner2009} are not completely
adequate. A material model \citep{Tong2005} solves these limitations, but the associated drawbacks (complex capture procedure
involved, computational costs, poor image and structure variability),
made its widespread application very difficult.

In this paper we propose to apply Direct Volume Rendering (DVR)
\citep{Levoy1988,Kruger2003, Kratz2006} on a scalar field to render
the bread crumb structure. DVR applies ray marching through a volume
accumulating different properties for each pixel. The method does not
use intermediate structures, simplifying the modelling
process. In addition, the bread crumb shape can be defined in
real time on the GPU, with the possibility of performing arbitrary cuts and
slices of the 3D structure in real time. Also, the
bread crust can be easily defined along with its own properties like
colour and translucency, using transfer functions. We obtain satisfactory results at real time rates.

Authors organise this paper as follows. In section 2 we introduce the theory of
particle systems, dynamical systems and DVR. In section
3 we show and discuss the results. In section 4 we summarise the conclusions,
as well as possible future works.

\section{MATERIALS AND METHODS}

\subsection{Particle systems}

Early approaches in computer graphics represented objects using Euclidean geometry. In other words, combining points, lines, surfaces, and other simple primitives. Nevertheless, it is difficult to capture details of natural structures with this approach. Other approaches such as fractal geometry \citep{Mandelbrot83} describes natural phenomena more adequately.

Particle systems \citep{Reeves83} deals with phenomena which have no well defined surface, like water,
smoke, and fire. Particle systems are composed of entities called {\em
  particles} that evolve properties over time. For instance, the method can render fireworks defining a common space position, and after
each time step modifying each particle position following a parabola, with different
particles following slightly different parabolas. The method obtains an animation. Particle systems renders fire and other effects modifying properties as colour, size and direction. Particles can also affect each other.

In a previous work \citep{Baravalle2011}, we employed particle systems for texture synthesis. Each particle had an initial random position in an image, and evolved avoiding other particles. We obtained adequate results for wood and painting textures. The growing functions were random, vertical, horizontal and diagonal. We propose to emulate the bread making process by extending it into space, using a system of differential equations to control the particles growth. The result is a 3D texture representing this material. 

\subsubsection{Modelling algorithm}
This algorithm produces a geometry for rendering. Therefore, instead of delivering the colour of a particular space position it will generate a scalar field composed of $0$s and $1$s ($0$: air, $1$: mass). This representation is adequate for DVR.

The system consists of a set of particles $P$, 

\begin{equation}
  P = \{p_{1}, ... , p_{n}\}, n  \in \mathbb{N},
\end{equation}

\noindent a lattice $L_{N\times N \times N}, N \in \mathbb{N} $ (initially $L_{xyz}=1$) of mass and air, and a lattice $L2_{N\times N \times N}$, (initially $L2_{xyz}=-1$), of positions and particle ownership ($i$ if the lattice element belongs to the contour or interior of the particle $i$).

Each element in $P$ has the following properties:

\begin{equation}
  p_{i} = \{O_{i}, C_{i}\}, 1 \le i \le n,
\end{equation}

\noindent where:

\begin{itemize}
\item $O_{i} = \{o_{1}, ... , o_{n_{i}}\}$: (Occupied) vector (set) of occupied positions by the particle in $L$.

\item $C_{i} = \{c_{1}, ... , c_{m_{i}}\}$: (Contour) vector (set) of positions representing the particle {\em contour} in $L$. The vector $O$ represents the positions affected by the particle, and the contour $C$ ensure avoidance with other particles.
\end{itemize}

The algorithm works as follows. When $t = 0$, a set of particles take random lattice positions. Each particle adds its position to $O$ and the surrounding positions to $C$. Then, for each $t$, each particle chooses a position on its contour. If the position lies in the contour of any other particle ($L2_{position} <> i$ and $L2_{position} > -1$), it is discarded and the process selects another contour position. If that position is free ($L2_{position} = i$ or $L2_{position} = -1$), the particle adds the position to its $O$ and updates its contour $C$ and the lattices. If the contour vector is empty, the particle {\em dies}, since it cannot grow anymore in the simulation.

Termination of the algorithm is possible at any $t$. The user can stop at a particular event, for instance, when the $L2$ lattice is full ($L2_{xyz} <> -1$ in any lattice position), since no progress can be made.

The method produces different structures varying the contour size (see Fig.~\ref{fg:fig1}). The image shows 2D output examples (for better understanding) of random growing particles. The contour size determines the white region among particles (mass) (the {\em width} of the white area). Resulting images seem to form voronoi-like patterns.


\begin{figure*}[htb!]
  \centerline{\includegraphics[scale=0.22]{fig1.pdf}}
  \caption{Different values for the contour parameter. Left: contour = 1, middle: contour = 2, right: contour = 4.}
  \label{fg:fig1}
\end{figure*}

The algorithm outputs the $L$ lattice. Next section establishes the system employed to evolve the particles over time.

\subsection{Dynamical systems}

Differential Equations manages the
difficulty (or impossibility) of finding analytical equations for
dynamical processes \citep{Strogatz2001}. Studies model dynamical phenomena by defining differential equations representing its behaviour. They simulate the evolution of the system and derive approximate solutions. Dynamical systems deals with processes such as economics, heat transfer, and fluids. With the development of computers, the field obtained insight into areas which were impossible before, such as Fractals \citep{Mandelbrot83}
and Chaos.

Mathematicians use numerical approximations to solve dynamical systems. The complexity of the problem and the number of equations involved changes its computational costs. We propose to employ a sub field of differential equations, Ordinary Differential Equations (ODE), for the purposes of this work. In ODEs, time is the only independent variable.

ODEs can be represented using the following set of equations:
\begin{equation} \label{eq:simple}  
  \begin{aligned}
    \dot{x_{1}} = f_{1}(x_{1},\ldots,x_{n}),\\
    \ldots\\
    \dot{x_{n}} = f_{n}(x_{1},\ldots,x_{n}),
  \end{aligned}
\end{equation}

\noindent where $\dot{x_{i}}$ represents the derivative of $x_{i}$ with respect
to $t$. The variables $x_{i}$ and the functions $f_{i}$
differ for each problem. In this work, each variable represents a
Cartesian coordinate in space, {\em i.e.,} $x_{1}$ is $x$, $x_{2}$ is
$y$ and $x_{3}$ is $z$ and we will define the set of $f_{i}$ to capture the bread crumb structure. The next section shows how these
systems can describe the evolution of a particle system.

\subsection{Particle evolution using dynamical systems}

Human perception can detect patterns in bread crumb structure (see
Fig.~\ref{fg:fig2}). First, bubble shape tends
to follow the crust shape. This is not casual, since temperature in
baking affects the bubbles' shape \citep{Scanlon2001}, stretching
them following its walls. Also, the entire
structure has a fluid-like appearance. Indeed, this is the case in
early stages of the baking process. At some point, the viscosity
of the dough decreases and the bubbles stop growing and
coalescing.

\begin{figure*}[htb!]
  \centerline{\includegraphics[scale=0.45]{fig2}}
  \caption{Images of real bread slices}
  \label{fg:fig2}
\end{figure*}

Dynamical systems produce natural shapes. If the domain is an image, the system outputs circles and spirals (see
Fig.~\ref{fg:fig3}). Three different set of equations
describe each image dynamics. For instance, the following set of equations produce the left
image:

\begin{equation} \label{eq:simple}  
  \begin{aligned}
    \dot{x} &= x^{2}-y^{2}+1,\\
    \dot{y} &= 2xy+1.
  \end{aligned}
\end{equation}


\begin{figure*}[htb!]
  \centerline{\includegraphics[scale=0.28]{fig3}}
  \caption{Dynamical systems in the plane.}
  \label{fg:fig3}
\end{figure*}


We chose random positions solving the system at each time step with a fourth order Runge-Kutta solver, determining the new trajectory direction. In the left image, an {\em attractor} attracts positions in the left-upper quadrant. A set of points can also form an attractor (right image).

Particles following trajectories produce patterns in the plane or space. To make a particle follow a trajectory, we solve the dynamical system at the current particle position, and we chose the contour position which best approximates that solution. The dynamical system defines a vector field for the particles.

Fig.~\ref{fg:fig4} shows particles' growing direction following this vector field. In the
images, from left to right, we decrement the trajectories' {\em randomness}. The parameter randomness set to $0.1$ produces the right image, meaning
it forces bubbles to follow the dynamical system
trajectories with a probability of $0.9$. We define this probability as
$1-randomness$, with $0 \leq randomness \leq 1$. The dynamical system
is the same as the right image in Fig.~\ref{fg:fig3}.  Patterns result adequate for use in bread images, cakes and other baked foods. We can define different useful structures employing different set of equations and different parameters for the
particle systems (particles' lifetime, randomness).


\begin{figure*}[htb!]
  \centerline{\includegraphics[scale=0.21]{fig4}}
  \caption{Particle systems following dynamical systems . Effect of the randomness parameter. From left to right, randomness: 0.3,0.2,0.1 respectively. }
  \label{fg:fig4}
\end{figure*}

Next section shows how we render these evolved particles.

\subsection{Rendering algorithm}

In this section we expose the theory and implementation of the DVR algorithm.

\subsubsection{Direct volume rendering}

The technique of direct volume rendering provides a
2-dimensional representation of a volume defined by a discrete
3-dimensional density function. The method casts rays from a camera in a virtual scene and uses the density function to
compute the amount of light that the camera receives from each
ray direction. The method samples the density function
along the ray to approximate the effect of different light
phenomena such as extinction, transmittance and scattering, among
others. The technique then uses the lighting information gathered from these rays to compute pixel colours in the final image.

Radiance is the amount of light that passes, or is emitted, from a
point and falls within a given solid angle. DVR assumes an emissive media, so when inspecting the amount of light received, it actually approximates
the radiance received from a distant point along the ray direction. The technique approximates the radiance value by the addition of the background radiance and the radiance that emits the media along the ray direction \citep{Kratz2006} : 

\begin{equation} \label{eq:general_radiance}  
  L(p_n) = L_b + \int_{p_0}^{p_n} \frac{\partial L(t)}{\partial p} \, dt,
\end{equation}

\noindent where $L_b$ is the background radiance, and $p_0$, $p_n$ are the
closest and furthest visible points along the ray direction,
respectively, $L(t)$ is the radiance at point $t$, and
$\partial p$ is the distance between sampled points. To compute $L(p_n)$, the integral is approximated by a sum.

Extinction is the loss of photons in a ray shaft due to absorption in
the participating media and scattering to other directions. Some of
the photons will collide with the particles in the
surrounding media and it will absorb and transform to energy, mostly
heat. Others will bounce and move along other directions. The method uses an absorption coefficient for the media to approximate this, $k_a$
and a scattering coefficient $k_s$. If we neglect the scattering effect, the formula for the amount of radiance absorbed over a ray segment is:

\begin{equation} \label{eq:radiance_absorption}  
    L_b \ \displaystyle e^{-\int_{p_0}^{p_n} k_a(t) \, dt}.
\end{equation}

We introduce the value $\int_{p_i}^{p_j} k_a(t) \, dt$, the absorption coefficient, and we will refer it as $\tau_{(p_i, p_j)}$.

Transmittance is complementary to extinction. It describes
the amount of light passing through a media in a given
direction. The transmittance value along two points $p_i$ and $p_j$
is:

\begin{equation} \label{eq:general_radiance}  
  T(p_i,p_j) = e^{-\tau_{(p_i, p_j)}}.
\end{equation}

If we assume constant light emission ($\rho$) in the volume, our initial radiance estimate becomes:

\begin{equation} \label{eq:ray_radiance}  
  L(p_n) = L_b \ e^{-\tau(p_0, p_n)} + \int_{p_0}^{p_n} \rho \ e^{-\tau(t,p_n)} \, dt.
\end{equation}

This means that the radiance along points $p_0$ and
$p_n$ is the attenuated remaining background radiance plus the
attenuated emission at every ray point.

DVR samples a volume density function at
regular intervals, approximates the transmittance along those points and computes the amount of light reaching the camera along the ray direction. The computation replaces the integral sum by a discrete sum over the length of the ray intersecting the volume.

Other effects can be accounted for, augmenting the final image's fidelity, as well as the technique's computing cost. Some of these effects are phase, incidental scattering, and
out-scattering. The basis of our rendering algorithm uses the simplified
transmittance only model to achieve real time frame rates.

\subsubsection{Implementation}

We create a demo application \footnote{available at
  \emph{\url{https://www.github.com/rbaravalle/Pysys}}} that uses the particle
system described, generating a volume texture. We use this volume texture to shade a cube with a DVR based shader. This demo shows
that the proposed method is compatible with current
rasterization-based real-time GPU rendering pipelines, providing a
realistic looking material and shadow-map based real-time
shadows. The material techniques we propose in this
article  can easily be integrated into any shader-based 3D engine with
minimal modifications.

We define a unit cube mesh for our model. The vertex shader code is very simple, providing only geometry information to the fragment shader, which does the bulk of the
computations. 

The shader computes a ray with the fragment position as origin and
the direction from the camera position to the fragment as the ray
direction. The code samples the volume texture at regular intervals in the ray
 and uses this to accumulate transmittance in the path. The computation ends if the transmittance falls below a threshold value or the ray exits the cube.

We generate a secondary ray at each step to compute the transmittance towards the light source. This information approximates the amount of light reaching the sample point, allowing to naturally perform self shadowing within the model.

We shade the pixel using the primary and secondary ray transmittance information. At this point, different artistic considerations may be applied to yield different
looking materials. For instance, we achieve a crumb-crust looking by assigning a darker colour to crust bread regions, and a soft yellowish colour to the crumb regions. We also use a very faint specular component. The lighting secondary rays provides a more detailed structure.

Our demo allows to modify parameters such as the
transmittance coefficient, the transmittance threshold,
the colour assigned to the crumb and the addition of a specular
highlight. This has the additional consequence of
producing images that resemble other porous materials,
such as sponges.

\subsection{Crust and cuts}
A function defines whether a volume point is part of the crust
or crumb. For instance, a cylindrical bread may define
a crust position when it has certain distance to the volume centre, and crumb otherwise. Another function defines whether a point should be
considered empty air. This allows an easy way to define bread slices (see Fig.~\ref{fg:fig5}, \ref{fg:fig6}).

This process should be extended for artists since the programmer needs a mathematical knowledge to define regions. Next section shows and discusses the results of these processes.

\section{RESULTS AND DISCUSSION}

In this section, we show different rendering results and computing times. We also briefly discuss the results.

\subsection{Rendering results}

This section shows several images that we obtained with the proposed
method. We employed a nVidia GTX 480 ($480$ cores), which
is a typical configuration for home computers. The CPU is an Intel(R)
Core(TM) i5-2300 CPU (quad core). The screen resolution is
$1440\times990$ pixels. We obtained different images with high bread resemblance. We obtained different bread types varying colours
and transmittance parameters (see Fig.~\ref{fg:fig5}). The centre image shows patterns produced by our particle system. In that case, the particles' lifetime differs for particles allowing bubbles of different sizes.

\begin{figure*}[htb!]
  \centerline{\includegraphics[scale=0.3]{fig5}}
  \caption{Real time rendered breads. The right image shows a bread which has no crust. }
  \label{fg:fig5}
\end{figure*}

We sinthesised other materials (see
Fig.~\ref{fg:fig6}) varying different
models parameters. The method allowed to render a sliced pudding, a slice
of cake, and a sponge. They have been
easily derived by changing the colour and the structure of the volume. When yeast is unnecesary in the manufacturing process, we used a random volume texture (sponge).

Back illumination is also present in the model (see Fig.~\ref{fg:fig7}): the render show the light propagation in the medium when illuminated from behind.

\begin{figure*}[htb!]
  \centerline{\includegraphics[scale=0.3]{fig6}}
  \caption{Real time rendered materials. Left: pudding, middle: cake, right: sponge. }
  \label{fg:fig6}
\end{figure*}



\begin{figure*}[htb!]
  \centerline{\includegraphics[scale=0.25]{fig7}}
  \caption{Sponge showing back illumination in the model. }
  \label{fg:fig7}
\end{figure*}


\subsection{Computing times}
Most images showed real time rates (FPS over 30), see Table~\ref{tab:n1}.

Two parameters are responsible for most of the computations: the transmittance coefficient and the steps count. A low transmittance produces a more transparent material making the ray accumulate more information, augmenting the computing time. We experimentally found that values above $100$ steps give reasonably images in all cases. The process automatically scales with the number of GPU processors, so the fps count will increment in more powerful GPUs.

\begin{table}[htb]
\centering
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline &  Bread 1 & Bread 2 & Bread 3 & Pudding & Cake & Sponge \\
\hline
\hline
 mean FPS  & 32.2 &  75.5 &  45.2 & 28.5 &  54.2 & 29.7\\
\hline
 Steps &  140 &  140 &  140 & 256 &  140 & 256 \\
\hline
 Transmittance &  15 &  15 &  15 & 15 &  15 & 2.25 \\
\hline
\end{tabular}
\caption{Computing times and key parameters for the images obtained. }
\label{tab:n1}
\end{table}

\subsection{Discussion}
To the best of the authors' knowledge, this is the first attempt to convincingly render bread crumb and other materials in real time without introducing complex intermediate processes (capture, mesh generation, precomputation, post-process). Literature shows previous approaches to bread rendering\citep{Cho2007}, but comparisons with this technique could not be established since no details are explained (computing times, render method).

The method shows easy integration with shader based engines. The computed fragment depth allows a natural integration in scenes.

Computing times show an excellent performance which mostly depends on
the steps count and the transmittance coefficient. Real
time rates are always reached except when the image encompasses a big portion
of the screen, since the approach is largely fragment-shader bound.

The method will be extended in number of ways, outlined at the end of this paper.


\section{CONCLUSIONS}

In this paper we apply the transmittance DVR model in the GPU to a 3D scalar field representing the bread crumb structure, obtaining realistic bread crumb images. We model this structure using particle systems and dynamical systems. A numerical simulation is employed to solve the resulting set of equations which represents the dynamical system. Results show high fidelity images in real time, suitable for application in several areas, such as serious games \citep{Susi2007} and photo-realistic rendering. This procedure does not present the drawbacks of other state of the art methods, such as capture processes or mesh generation.

The main method disadvantage is resolution, since close look-ups of the structure could lead to homogeneous areas due to hardware constraints, {\em i.e.}, the GPU is texture size limited. This disadvantage is not exclusive of our method. We will employ a number of possible solutions to overcome this problem, such as setting different volume textures depending on the camera distance to the volume. 

As possible continuations of this work, we may extend DVR to handle other phenomena such as indirect illumination and sub surface scattering, enhancing the resulting images. Also, partial differential equations will be employed to implement the baking process of bread \citep{Purlis2012}. Other porous materials such as cheeses will be investigated. Another interesting work will be to define primitives for crumb and crust modelling (shapes and intersections), enabling artists to define its shape.

%Template files in TeX, \LaTeX{} and MS-Word may be found at the
%AMCA web site: \url{http://www.amcaonline.org.ar}. 
%Remember: {\bf Do not number the pages.}
%
\bibliography{eniefbib}
\end{document}
% $Id: amcapaper.tex,v 1.23 2006/08/14 16:58:45 mstorti Exp $
